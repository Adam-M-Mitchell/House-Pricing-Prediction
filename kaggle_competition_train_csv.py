# -*- coding: utf-8 -*-
"""Kaggle Competition Train.csv

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/123V9y01BbZQ2-61a1c7XIJP8fJd8h4c0
"""

# Importing the libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Reading the file called train.csv
df=pd.read_csv('train.csv')

# Showing the first 5 rows of all the 81 variables
df.head()

# Searches the variables data and creating a counter for each one. As it finds 
# a null or missing data it is recording it in the counter

df.isnull().sum()

# Example code for showing a variables data type 
df['MSZoning'].value_counts()

# Counts the number of rows and collums
df.shape

# Shows all variables and their data type
df.info()

# Filling in the missing values

df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mode()[0])

df.drop(['Alley'],axis=1,inplace=True) # Dropping the value called Alley as its  empty

# Assigning the value 0 to BsmtCond and BsmtQual

df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])
df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])

# Assigning the value 0 to FireplaceQu and GarageType 

df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])
df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])

df.drop(['GarageYrBlt'],axis=1,inplace=True) # Droping the variable GarageYrBlt

# Assigning 0 to the following variables

df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])
df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])
df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])

# Dropping the following variables

df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)

# Counting the number of rows and avaliable variables

df.shape

# Dropping variable called ID

df.drop(['Id'],axis=1,inplace=True)

## Shows all the current variables and their data type

df.isnull().sum()

# Assigning 0 to the following empty variables

df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])
df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])

# Showing number of all variables

df.shape

# Showing a table of all remaining variables

df.head()

# Categorical features of the document called train.csv
 # Making part 1 of a table

columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',
         'Condition2','BldgType','Condition1','HouseStyle','SaleType',
        'SaleCondition','ExterCond',
         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',
        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',
         'CentralAir',
         'Electrical','KitchenQual','Functional',
         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']

# Counting the number of collums in table created above

len(columns)

# Creating a function that prints and reads the all the avaliable data given that has been edited

def category_multcols(multcolumns):
    df_final=final_df
    i=0
    for fields in multcolumns:
        print(fields)
        df1=pd.get_dummies(final_df[fields],drop_first=True)
        final_df.drop([fields],axis=1,inplace=True)
        if i==0:
            df_final=df1.copy()
        else:
            df_final=pd.concat([df_final,df1],axis=1)
        i=i+1
       
    df_final=pd.concat([final_df,df_final],axis=1) 
    return df_final

main_df=df.copy()

# Combining the test data and the train data

test_df=pd.read_csv('Handledtest.csv')

test_df.shape

test_df.head()

final_df=pd.concat([df,test_df],axis=0)

#Calculating all avaliable IDs Salesprice
final_df['SalePrice']

#Showing final Variable number and rows
final_df.shape

# Showing all used Variables in both documents

final_df=category_multcols(columns)

#Showing variable numbers used 
final_df.shape

# Removing Duplicated collums

final_df =final_df.loc[:,~final_df.columns.duplicated()]

# Showing variable numbers used
final_df.shape

# Final table with all information

final_df.head()

# Testing the data

df_Train=final_df.iloc[:1422,:]
df_Test=final_df.iloc[1422:,:]

df_Test.drop(['SalePrice'],axis=1,inplace=True)

X_train=df_Train.drop(['SalePrice'],axis=1)
y_train=df_Train['SalePrice']

# Showing train variable table

df_Train.head()

# Showing test variable table

df_Test.head()

import xgboost
classifier=xgboost.XGBRegressor()
classifier.fit(X_train,y_train)

from sklearn.ensemble import RandomForestRegressor

y_pred=classifier.predict(df_Test)

y_pred

df_Train.shape

pred=pd.DataFrame(y_pred)
sub_df=pd.read_csv('sample_submission.csv')
datasets=pd.concat([sub_df['Id'],pred],axis=1)
datasets.collums=['Id','SalePrice']
datasets.to_csv('sample_submission.csv',index=False)